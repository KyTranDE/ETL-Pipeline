{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "\n",
    "# Kh√≥a c·ªßa t·∫≠p h·ª£p\n",
    "redis_set_key = \"unique_get_picker_ids\"\n",
    "\n",
    "# L·∫•y t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ t·ª´ t·∫≠p h·ª£p\n",
    "set_values = redis_client.smembers(redis_set_key)\n",
    "\n",
    "# In ra c√°c ph·∫ßn t·ª≠ v√† gi√° tr·ªã t∆∞∆°ng ·ª©ng\n",
    "for value in set_values:\n",
    "    decoded_value = value.decode('utf-8')\n",
    "    print(f\"Set member: {decoded_value}\")\n",
    "\n",
    "    # L·∫•y gi√° tr·ªã c·ªßa m·ªói kh√≥a t∆∞∆°ng ·ª©ng\n",
    "    redis_key = f\"match:{decoded_value}\"\n",
    "    match_value = redis_client.get(redis_key)\n",
    "    \n",
    "    if match_value:\n",
    "        match_value = json.loads(match_value.decode('utf-8'))\n",
    "        print(f\"Match data for {redis_key}: {match_value}\")\n",
    "    else:\n",
    "        print(f\"No data found for {redis_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "\n",
    "# Kh√≥a c·ªßa t·∫≠p h·ª£p\n",
    "redis_set_key = \"unique_get_picker_ids\"\n",
    "\n",
    "# L·∫•y t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ t·ª´ t·∫≠p h·ª£p\n",
    "set_values = redis_client.smembers(redis_set_key)\n",
    "\n",
    "# X√≥a c√°c ph·∫ßn t·ª≠ v√† c√°c kh√≥a t∆∞∆°ng ·ª©ng\n",
    "for value in set_values:\n",
    "    decoded_value = value.decode('utf-8')\n",
    "    print(f\"Deleting set member: {decoded_value}\")\n",
    "\n",
    "    # X√≥a kh√≥a t∆∞∆°ng ·ª©ng v·ªõi m·ªói ph·∫ßn t·ª≠\n",
    "    redis_key = f\"match:{decoded_value}\"\n",
    "    redis_client.delete(redis_key)\n",
    "    print(f\"Deleted key: {redis_key}\")\n",
    "\n",
    "# X√≥a ch√≠nh t·∫≠p h·ª£p\n",
    "redis_client.delete(redis_set_key)\n",
    "print(f\"Deleted set: {redis_set_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "\n",
    "# Kh√≥a c·ªßa t·∫≠p h·ª£p\n",
    "redis_set_key = \"unique_get_picker_ids\"\n",
    "def delete_redis_key(key_pattern):\n",
    "    keys = redis_client.keys(key_pattern)\n",
    "    if keys:\n",
    "        redis_client.delete(*keys)\n",
    "        print(f\"Deleted keys: {keys}\")\n",
    "    else:\n",
    "        print(\"No keys found to delete.\")\n",
    "\n",
    "delete_redis_key(\"Picker*\")  # X√≥a c√°c key Redis tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "\n",
    "# Kh√≥a c·ªßa t·∫≠p h·ª£p\n",
    "redis_set_key = \"unique_get_picker_ids\"\n",
    "\n",
    "# L·∫•y t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ t·ª´ t·∫≠p h·ª£p\n",
    "set_values = redis_client.smembers(redis_set_key)\n",
    "\n",
    "# X√≥a c√°c ph·∫ßn t·ª≠ v√† c√°c kh√≥a t∆∞∆°ng ·ª©ng\n",
    "for value in set_values:\n",
    "    decoded_value = value.decode('utf-8')\n",
    "    print(f\"Deleting set member: {decoded_value}\")\n",
    "\n",
    "    # X√≥a kh√≥a t∆∞∆°ng ·ª©ng v·ªõi m·ªói ph·∫ßn t·ª≠\n",
    "    redis_key = f\"Picker{decoded_value}\"\n",
    "    redis_client.delete(redis_key)\n",
    "    print(f\"Deleted key: {redis_key}\")\n",
    "\n",
    "# X√≥a ch√≠nh t·∫≠p h·ª£p\n",
    "redis_client.delete(redis_set_key)\n",
    "print(f\"Deleted set: {redis_set_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_catche_redis(redis_set_key):\n",
    "    # K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "    redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "\n",
    "    # L·∫•y t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ t·ª´ t·∫≠p h·ª£p\n",
    "    set_values = redis_client.smembers(redis_set_key)\n",
    "\n",
    "    # X√≥a c√°c ph·∫ßn t·ª≠ v√† c√°c kh√≥a t∆∞∆°ng ·ª©ng\n",
    "    for value in set_values:\n",
    "        decoded_value = value.decode('utf-8')\n",
    "        print(f\"Deleting set member: {decoded_value}\")\n",
    "\n",
    "        # X√≥a kh√≥a t∆∞∆°ng ·ª©ng v·ªõi m·ªói ph·∫ßn t·ª≠\n",
    "        redis_key = f\"match:{decoded_value}\"\n",
    "        redis_client.delete(redis_key)\n",
    "        print(f\"Deleted key: {redis_key}\")\n",
    "\n",
    "    # X√≥a ch√≠nh t·∫≠p h·ª£p\n",
    "    redis_client.delete(redis_set_key)\n",
    "    print(f\"Deleted set: {redis_set_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.header import read_headers_from_config\n",
    "from Utils.params import read_params_from_config\n",
    "from config.teams import CODE2TEAMNAME\n",
    "import pandas as pd\n",
    "from Utils.postgres_tool import PostgresTool\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import requests\n",
    "import redis \n",
    "import emoji\n",
    "import yml\n",
    "\n",
    "config = yml.read_config(\"./config/config.yml\")\n",
    "\n",
    "# headers = read_headers_from_config(\"./config/config.ini\")\n",
    "# params = read_params_from_config(\"./config/config.ini\")\n",
    "# url_factmath = config['url']['URL_FACT_MATH']\n",
    "\n",
    "headers = config['headers']\n",
    "params = config['params']\n",
    "url_factmath = config['url']['URL_FACT_MATH']\n",
    "db_config = {\n",
    "    \"host\": config['database']['DB_SV_HOSTS'],\n",
    "    \"port\": config['database'].getint('DB_SV_PORT'),\n",
    "    \"user\": config['database']['DB_SV_USER'],\n",
    "    \"password\": config['database']['DB_SV_PASSWORD'],\n",
    "    \"database\": config['database']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "redis_set_key = \"unique_match_ids\"\n",
    "\n",
    "def fetch_data_from_url(url, headers, params):\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()  \n",
    "    return response.json()\n",
    "\n",
    "def process_data(data, id_idx):\n",
    "    for i in data:\n",
    "        datas = {\n",
    "            \"id\": i[\"id\"],\n",
    "            \"home_team_id\": i[\"home_team_id\"],\n",
    "            \"away_team_id\": i[\"road_team_id\"],\n",
    "            \"status\": i[\"game_state\"],\n",
    "            \"home_team_score\": i[\"home_team_score\"],\n",
    "            \"away_team_score\": i[\"road_team_score\"],\n",
    "            \"live_home_team_score\": i[\"live_home_team_score\"],\n",
    "            \"live_away_team_score\": i[\"live_road_team_score\"],\n",
    "            \"home_team_spread\": i[\"home_team_spread\"],\n",
    "            \"away_team_spread\": i[\"road_team_spread\"],\n",
    "            \"point_total\": i[\"over_under\"],\n",
    "            \"date_id\": id_idx,\n",
    "            \"kickoff_time\": i[\"kickoff\"].split('T')[0],\n",
    "            \"sport_id\": \"mlb\",\n",
    "        }\n",
    "        yield datas\n",
    "\n",
    "def get_us_date(timezone_name='US/Eastern'):\n",
    "    us_timezone = pytz.timezone(timezone_name)\n",
    "    utc_now = datetime.now(pytz.utc)\n",
    "    us_now = utc_now.astimezone(us_timezone)\n",
    "    return us_now.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_math_data(db_config, sport_id, season):\n",
    "    conn = PostgresTool(**db_config)\n",
    "    CURRENT_DATE_US = get_us_date()\n",
    "\n",
    "    query = f\"SELECT idx, id FROM date_id WHERE date_play = '{CURRENT_DATE_US}' AND sport_id = '{sport_id}' AND season = '2024'\"\n",
    "    idx = conn.query(query, False)[0][0]\n",
    "    id_idx = conn.query(query, False)[0][1]\n",
    "    querys1 = f\"\"\"SELECT COUNT(*) FROM \"match\" m WHERE m.date_id = '{id_idx-1}' AND m.status != 'Final'\"\"\"\n",
    "    count = conn.query(querys1, False)[0][0]\n",
    "    if count != 0:\n",
    "        id_idx = id_idx - 1\n",
    "        idx = idx - 1\n",
    "    data = fetch_data_from_url(url_factmath.format(idx), headers, params)\n",
    "    datas = process_data(data, id_idx)\n",
    "    for i in datas:\n",
    "        yield i\n",
    "    conn.close()\n",
    "\n",
    "def main(db_config):\n",
    "    datas = get_math_data(db_config, \"mlb\", \"2024\")  # sport_id = \"mlb\", season = \"2024\"\n",
    "\n",
    "    for data in datas:\n",
    "        redis_key = f\"match:{data}\"\n",
    "        exists = redis_client.sismember(redis_set_key, str(data))\n",
    "        if not exists:\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o Redis Set\n",
    "            redis_client.sadd(redis_set_key, str(data))\n",
    "            redis_client.expire(redis_set_key, 60*60*24)  # `60*60*24` seconds = 1 day\n",
    "            redis_client.setex(redis_key, 60*60*24, str(data))\n",
    "            # Chuy·ªÉn ƒë·ªïi l·∫°i chu·ªói ƒë·∫∑c bi·ªát th√†nh None tr∆∞·ªõc khi ƒë·∫©y d·ªØ li·ªáu v√†o DB\n",
    "            data = {k: (v if v != \"None\" else None) for k, v in data.items()}\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o DB\n",
    "            conn = PostgresTool(**db_config)\n",
    "            conn.push_data('match', data)\n",
    "            conn.close()\n",
    "        else:\n",
    "            print(emoji.emojize(f\"ü¶Ñüë©üèª‚Äçüíª Duplicate data found, skipping: {data} ü¶Ñ\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(db_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import requests\n",
    "import emoji\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from Utils.header import read_headers_from_config\n",
    "from Utils.params import read_params_from_config\n",
    "from Utils.postgres_tool import PostgresTool\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "\n",
    "headers = read_headers_from_config(\"./config/config.ini\")\n",
    "params = read_params_from_config(\"./config/config.ini\")\n",
    "url_factmath = config['url']['URL_FACT_MATH']\n",
    "\n",
    "db_config = {\n",
    "    \"host\": config['database']['DB_SV_HOSTS'],\n",
    "    \"port\": config['database'].getint('DB_SV_PORT'),\n",
    "    \"user\": config['database']['DB_SV_USER'],\n",
    "    \"password\": config['database']['DB_SV_PASSWORD'],\n",
    "    \"database\": config['database']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "db_config_sv = {\n",
    "    'host': config['database_sv']['DB_SV_HOSTS'],\n",
    "    'port': config['database_sv'].getint('DB_SV_PORT'),\n",
    "    'user': config['database_sv']['DB_SV_USER'],\n",
    "    'password': config['database_sv']['DB_SV_PASSWORD'],\n",
    "    'database': config['database_sv']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "redis_set_key = \"unique_match_ids\"\n",
    "\n",
    "def fetch_data_from_url(url, headers, params):\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()  \n",
    "    return response.json()\n",
    "\n",
    "def process_data(data, id_idx):\n",
    "    for i in data:\n",
    "        yield {\n",
    "            \"id\": i[\"id\"],\n",
    "            \"home_team_id\": i[\"home_team_id\"],\n",
    "            \"away_team_id\": i[\"road_team_id\"],\n",
    "            \"status\": i[\"game_state\"],\n",
    "            \"home_team_score\": i[\"home_team_score\"],\n",
    "            \"away_team_score\": i[\"road_team_score\"],\n",
    "            \"live_home_team_score\": i[\"live_home_team_score\"],\n",
    "            \"live_away_team_score\": i[\"live_road_team_score\"],\n",
    "            \"home_team_spread\": i[\"home_team_spread\"],\n",
    "            \"away_team_spread\": i[\"road_team_spread\"],\n",
    "            \"point_total\": i[\"over_under\"],\n",
    "            \"date_id\": id_idx,\n",
    "            \"kickoff_time\": i['additional_data'][\"DateTime\"],\n",
    "            \"sport_id\": \"mlb\",\n",
    "        }\n",
    "\n",
    "def get_us_date(timezone_name='US/Eastern'):\n",
    "    us_timezone = pytz.timezone(timezone_name)\n",
    "    utc_now = datetime.now(pytz.utc)\n",
    "    us_now = utc_now.astimezone(us_timezone)\n",
    "    return us_now.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_math_data(db_config, sport_id, season):\n",
    "    conn = PostgresTool(**db_config)\n",
    "    current_date_us = get_us_date()\n",
    "\n",
    "    query = f\"SELECT idx, id FROM date_id WHERE date_play = '{current_date_us}' AND sport_id = '{sport_id}' AND season = '2024'\"\n",
    "    idx, id_idx = conn.query(query, False)[0]\n",
    "\n",
    "    querys1 = f\"SELECT COUNT(*) FROM match WHERE date_id = '{id_idx-1}' AND status = 'Scheduled'\"\n",
    "    count = conn.query(querys1, False)[0][0]\n",
    "    if count != 0:\n",
    "        id_idx -= 1\n",
    "        idx -= 1\n",
    "\n",
    "    data = fetch_data_from_url(url_factmath.format(idx), headers, params)\n",
    "    yield from process_data(data, id_idx)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "def main(db_config):\n",
    "    datas = get_math_data(db_config, \"mlb\", \"2024\")\n",
    "\n",
    "    for data in datas:\n",
    "        redis_key = f\"match:{data['id']}\"  # S·ª≠ d·ª•ng id l√†m kh√≥a duy nh·∫•t\n",
    "        if not redis_client.sismember(redis_set_key, data['id']):\n",
    "            redis_client.sadd(redis_set_key, data['id'])\n",
    "            redis_client.expire(redis_set_key, 60*60*24)  # 1 day expiration\n",
    "            redis_client.setex(redis_key, 60*60*24, str(data))\n",
    "            data = {k: (v if v != \"None\" else None) for k, v in data.items()}\n",
    "            conn = PostgresTool(**db_config)\n",
    "            conn.push_data('match', data)\n",
    "            conn.close()\n",
    "        else:\n",
    "            print(emoji.emojize(f\"ü¶Ñüë©üèª‚Äçüíª Duplicate data found, skipping: {data} ü¶Ñ\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(db_config)\n",
    "    main(db_config_sv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main backup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.header import read_headers_from_config\n",
    "from Utils.params import read_params_from_config\n",
    "from config.teams import CODE2TEAMNAME\n",
    "import pandas as pd\n",
    "import os\n",
    "import configparser\n",
    "from Utils.postgres_tool import PostgresTool\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import requests\n",
    "import redis \n",
    "import emoji\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "\n",
    "headers = read_headers_from_config(\"./config/config.ini\")\n",
    "params = read_params_from_config(\"./config/config.ini\")\n",
    "url_factmath = config['url']['URL_FACT_MATH']\n",
    "db_config = {\n",
    "    \"host\": config['database']['DB_SV_HOSTS'],\n",
    "    \"port\": config['database'].getint('DB_SV_PORT'),\n",
    "    \"user\": config['database']['DB_SV_USER'],\n",
    "    \"password\": config['database']['DB_SV_PASSWORD'],\n",
    "    \"database\": config['database']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "db_config_sv = {\n",
    "    'host': config['database_sv']['DB_SV_HOSTS'],\n",
    "    'port': config['database_sv'].getint('DB_SV_PORT'),\n",
    "    'user': config['database_sv']['DB_SV_USER'],\n",
    "    'password': config['database_sv']['DB_SV_PASSWORD'],\n",
    "    'database': config['database_sv']['DB_SV_DATABASE']\n",
    "}\n",
    "# K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "redis_set_key = \"unique_match_ids\"\n",
    "\n",
    "def fetch_data_from_url(url, headers, params):\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()  \n",
    "    return response.json()\n",
    "\n",
    "def process_data(data, id_idx):\n",
    "    for i in data:\n",
    "        datas = {\n",
    "            \"id\": i[\"id\"],\n",
    "            \"home_team_id\": i[\"home_team_id\"],\n",
    "            \"away_team_id\": i[\"road_team_id\"],\n",
    "            \"status\": i[\"game_state\"],\n",
    "            \"home_team_score\": i[\"home_team_score\"],\n",
    "            \"away_team_score\": i[\"road_team_score\"],\n",
    "            \"live_home_team_score\": i[\"live_home_team_score\"],\n",
    "            \"live_away_team_score\": i[\"live_road_team_score\"],\n",
    "            \"home_team_spread\": i[\"home_team_spread\"],\n",
    "            \"away_team_spread\": i[\"road_team_spread\"],\n",
    "            \"point_total\": i[\"over_under\"],\n",
    "            \"date_id\": id_idx,\n",
    "            \"kickoff_time\": i['additional_data'][\"DateTime\"],\n",
    "            \"sport_id\": \"mlb\",\n",
    "        }\n",
    "        yield datas\n",
    "\n",
    "def get_us_date(timezone_name='US/Eastern'):\n",
    "    us_timezone = pytz.timezone(timezone_name)\n",
    "    utc_now = datetime.now(pytz.utc)\n",
    "    us_now = utc_now.astimezone(us_timezone)\n",
    "    return us_now.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_math_data(db_config, sport_id, season):\n",
    "    conn = PostgresTool(**db_config)\n",
    "    CURRENT_DATE_US = get_us_date()\n",
    "\n",
    "    query = f\"SELECT idx, id FROM date_id WHERE date_play = '{CURRENT_DATE_US}' AND sport_id = '{sport_id}' AND season = '2024'\"\n",
    "    idx = conn.query(query, False)[0][0]\n",
    "    id_idx = conn.query(query, False)[0][1]\n",
    "    querys1 = f\"\"\"SELECT COUNT(*) FROM \"match\" m WHERE m.date_id = '{id_idx-1}' AND m.status = 'Scheduled'\"\"\"\n",
    "    count = conn.query(querys1, False)[0][0]\n",
    "    if count != 0:\n",
    "        id_idx = id_idx - 1\n",
    "        idx = idx - 1\n",
    "    data = fetch_data_from_url(url_factmath.format(idx), headers, params)\n",
    "    datas = process_data(data, id_idx)\n",
    "    for i in datas:\n",
    "        yield i\n",
    "    conn.close()\n",
    "\n",
    "def main(db_config):\n",
    "    datas = get_math_data(db_config, \"mlb\", \"2024\")  # sport_id = \"mlb\", season = \"2024\"\n",
    "\n",
    "    for data in datas:\n",
    "        redis_key = f\"match:{data}\"\n",
    "        exists = redis_client.sismember(redis_set_key, str(data))\n",
    "        if not exists:\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o Redis Set\n",
    "            redis_client.sadd(redis_set_key, str(data))\n",
    "            redis_client.expire(redis_set_key, 60*60*24)  # `60*60*24` seconds = 1 day\n",
    "            redis_client.setex(redis_key, 60*60*24, str(data))\n",
    "            # Chuy·ªÉn ƒë·ªïi l·∫°i chu·ªói ƒë·∫∑c bi·ªát th√†nh None tr∆∞·ªõc khi ƒë·∫©y d·ªØ li·ªáu v√†o DB\n",
    "            data = {k: (v if v != \"None\" else None) for k, v in data.items()}\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o DB\n",
    "            conn = PostgresTool(**db_config)\n",
    "            conn.push_data('match', data)\n",
    "            conn.close()\n",
    "        else:\n",
    "            print(emoji.emojize(f\"ü¶Ñüë©üèª‚Äçüíª Duplicate data found, skipping: {data} ü¶Ñ\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(db_config)\n",
    "    main(db_config_sv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import requests\n",
    "import emoji\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from Utils.header import read_headers_from_config\n",
    "from Utils.params import read_params_from_config\n",
    "from Utils.postgres_tool import PostgresTool\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "\n",
    "headers = read_headers_from_config(\"./config/config.ini\")\n",
    "params = read_params_from_config(\"./config/config.ini\")\n",
    "url_factmath = config['url']['URL_FACT_MATH']\n",
    "\n",
    "db_config = {\n",
    "    \"host\": config['database']['DB_SV_HOSTS'],\n",
    "    \"port\": config['database'].getint('DB_SV_PORT'),\n",
    "    \"user\": config['database']['DB_SV_USER'],\n",
    "    \"password\": config['database']['DB_SV_PASSWORD'],\n",
    "    \"database\": config['database']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "db_config_sv = {\n",
    "    'host': config['database_sv']['DB_SV_HOSTS'],\n",
    "    'port': config['database_sv'].getint('DB_SV_PORT'),\n",
    "    'user': config['database_sv']['DB_SV_USER'],\n",
    "    'password': config['database_sv']['DB_SV_PASSWORD'],\n",
    "    'database': config['database_sv']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "\n",
    "def fetch_data_from_url(url, headers, params):\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()  \n",
    "    return response.json()\n",
    "\n",
    "def process_data(data, id_idx):\n",
    "    for i in data:\n",
    "        yield {\n",
    "            \"id\": i[\"id\"],\n",
    "            \"home_team_id\": i[\"home_team_id\"],\n",
    "            \"away_team_id\": i[\"road_team_id\"],\n",
    "            \"status\": i[\"game_state\"],\n",
    "            \"home_team_score\": i[\"home_team_score\"],\n",
    "            \"away_team_score\": i[\"road_team_score\"],\n",
    "            \"live_home_team_score\": i[\"live_home_team_score\"],\n",
    "            \"live_away_team_score\": i[\"live_road_team_score\"],\n",
    "            \"home_team_spread\": i[\"home_team_spread\"],\n",
    "            \"away_team_spread\": i[\"road_team_spread\"],\n",
    "            \"point_total\": i[\"over_under\"],\n",
    "            \"date_id\": id_idx,\n",
    "            \"kickoff_time\": i['additional_data'][\"DateTime\"],\n",
    "            \"sport_id\": \"mlb\",\n",
    "        }\n",
    "\n",
    "def get_us_date(timezone_name='US/Eastern'):\n",
    "    us_timezone = pytz.timezone(timezone_name)\n",
    "    utc_now = datetime.now(pytz.utc)\n",
    "    us_now = utc_now.astimezone(us_timezone)\n",
    "    return us_now.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_math_data(db_config, sport_id, season):\n",
    "    conn = PostgresTool(**db_config)\n",
    "    current_date_us = get_us_date()\n",
    "\n",
    "    query = f\"SELECT idx, id FROM date_id WHERE date_play = '{current_date_us}' AND sport_id = '{sport_id}' AND season = '2024'\"\n",
    "    idx, id_idx = conn.query(query, False)[0]\n",
    "\n",
    "    querys1 = f\"SELECT COUNT(*) FROM match WHERE date_id = '{id_idx-1}' AND status = 'Scheduled'\"\n",
    "    count = conn.query(querys1, False)[0][0]\n",
    "    if count != 0:\n",
    "        id_idx -= 1\n",
    "        idx -= 1\n",
    "\n",
    "    data = fetch_data_from_url(url_factmath.format(idx), headers, params)\n",
    "    yield from process_data(data, id_idx)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "def main(db_config, redis_prefix):\n",
    "    redis_set_key = f\"{redis_prefix}_unique_match_ids\"\n",
    "    datas = get_math_data(db_config, \"mlb\", \"2024\")\n",
    "\n",
    "    for data in datas:\n",
    "        redis_key = f\"{redis_prefix}:match:{data}\"  # S·ª≠ d·ª•ng id l√†m kh√≥a duy nh·∫•t\n",
    "        exists = redis_client.sismember(redis_set_key, str(data))\n",
    "\n",
    "        if not exists:\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o Redis Set\n",
    "            redis_client.sadd(redis_set_key, str(data))\n",
    "            redis_client.expire(redis_set_key, 60*60*24)  # `60*60*24` seconds = 1 day\n",
    "            redis_client.setex(redis_key, 60*60*24, str(data))\n",
    "            # Chuy·ªÉn ƒë·ªïi l·∫°i chu·ªói ƒë·∫∑c bi·ªát th√†nh None tr∆∞·ªõc khi ƒë·∫©y d·ªØ li·ªáu v√†o DB\n",
    "            data = {k: (v if v != \"None\" else None) for k, v in data.items()}\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o DB\n",
    "            conn = PostgresTool(**db_config)\n",
    "            conn.push_data('match', data)\n",
    "            conn.close()\n",
    "        else:\n",
    "            print(emoji.emojize(f\"ü¶Ñüë©üèª‚Äçüíª {redis_prefix} Duplicate data found, skipping: {data} ü¶Ñ\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(db_config, \"db_config\")\n",
    "    main(db_config_sv, \"db_config_sv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main fix push error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import requests\n",
    "import emoji\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from Utils.header import read_headers_from_config\n",
    "from Utils.params import read_params_from_config\n",
    "from Utils.postgres_tool import PostgresTool\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "\n",
    "headers = read_headers_from_config(\"./config/config.ini\")\n",
    "params = read_params_from_config(\"./config/config.ini\")\n",
    "url_factmath = config['url']['URL_FACT_MATH']\n",
    "\n",
    "# config for database server bbsw\n",
    "db_config = {\n",
    "    \"host\": config['database']['DB_SV_HOSTS'],\n",
    "    \"port\": config['database'].getint('DB_SV_PORT'),\n",
    "    \"user\": config['database']['DB_SV_USER'],\n",
    "    \"password\": config['database']['DB_SV_PASSWORD'],\n",
    "    \"database\": config['database']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "# config for database server aws\n",
    "db_config_sv = {\n",
    "    'host': config['database_sv']['DB_SV_HOSTS'],\n",
    "    'port': config['database_sv'].getint('DB_SV_PORT'),\n",
    "    'user': config['database_sv']['DB_SV_USER'],\n",
    "    'password': config['database_sv']['DB_SV_PASSWORD'],\n",
    "    'database': config['database_sv']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "# connect to redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "\n",
    "def fetch_data_from_url(url, headers, params):\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()  \n",
    "    return response.json()\n",
    "\n",
    "def process_data(data, id_idx):\n",
    "    for i in data:\n",
    "        yield {\n",
    "            \"id\": i[\"id\"],\n",
    "            \"home_team_id\": i[\"home_team_id\"],\n",
    "            \"away_team_id\": i[\"road_team_id\"],\n",
    "            \"status\": i[\"game_state\"],\n",
    "            \"home_team_score\": i[\"home_team_score\"],\n",
    "            \"away_team_score\": i[\"road_team_score\"],\n",
    "            \"live_home_team_score\": i[\"live_home_team_score\"],\n",
    "            \"live_away_team_score\": i[\"live_road_team_score\"],\n",
    "            \"home_team_spread\": i[\"home_team_spread\"],\n",
    "            \"away_team_spread\": i[\"road_team_spread\"],\n",
    "            \"point_total\": i[\"over_under\"],\n",
    "            \"date_id\": id_idx,\n",
    "            \"kickoff_time\": i['additional_data'][\"DateTime\"],\n",
    "            \"sport_id\": \"mlb\",\n",
    "        }\n",
    "\n",
    "def get_us_date(timezone_name='US/Eastern'):\n",
    "    us_timezone = pytz.timezone(timezone_name)\n",
    "    utc_now = datetime.now(pytz.utc)\n",
    "    us_now = utc_now.astimezone(us_timezone)\n",
    "    return us_now.strftime('%Y-%m-%d')\n",
    "\n",
    "def delete_catche_redis(redis_set_key):\n",
    "    set_values = redis_client.smembers(redis_set_key)\n",
    "    for value in set_values:\n",
    "        decoded_value = value.decode('utf-8')\n",
    "        redis_key = f\"match:{decoded_value}\"\n",
    "        redis_client.delete(redis_key)\n",
    "\n",
    "    redis_client.delete(redis_set_key)\n",
    "\n",
    "def get_math_data(db_config, sport_id, season,redis_set_key):\n",
    "    conn = PostgresTool(**db_config)\n",
    "    current_date_us = get_us_date()\n",
    "\n",
    "    query = f\"SELECT idx, id FROM date_id WHERE date_play = '{current_date_us}' AND sport_id = '{sport_id}' AND season = '2024'\"\n",
    "    idx, id_idx = conn.query(query, False)[0]\n",
    "\n",
    "    query_check_status = f\"SELECT COUNT(*) FROM match WHERE date_id = '{id_idx-1}' AND status = 'Scheduled'\"\n",
    "    count = conn.query(query_check_status, False)[0][0]\n",
    "    if count != 0:\n",
    "        id_idx -= 1\n",
    "        idx -= 1\n",
    "    query_check_count = f\"SELECT COUNT(*) FROM match WHERE date_id = '{id_idx}' \"\n",
    "    count_check = conn.query(query_check_count, False)[0][0]\n",
    "    data = fetch_data_from_url(url_factmath.format(idx), headers, params)\n",
    "    \n",
    "    if count_check != 0 and count_check > len(data):\n",
    "\n",
    "        query_delete = f\"DELETE FROM match WHERE date_id = '{id_idx}'\"\n",
    "        conn.query(query_delete, False)\n",
    "        # clear all data in redis\n",
    "        delete_catche_redis(redis_set_key)\n",
    "    conn.close()\n",
    "\n",
    "    yield from process_data(data, id_idx)\n",
    " \n",
    "def main(db_config, redis_prefix):\n",
    "    redis_set_key = f\"{redis_prefix}_unique_match_ids\"\n",
    "    datas = get_math_data(db_config, \"mlb\", \"2024\",redis_set_key)\n",
    "\n",
    "    for data in datas:\n",
    "        redis_key = f\"{redis_prefix}:match:{data}\"  # S·ª≠ d·ª•ng id l√†m kh√≥a duy nh·∫•t\n",
    "        exists = redis_client.sismember(redis_set_key, str(data))\n",
    "\n",
    "        if not exists:\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o Redis Set\n",
    "            redis_client.sadd(redis_set_key, str(data))\n",
    "            redis_client.expire(redis_set_key, 60*60*24)  # `60*60*24` seconds = 1 day\n",
    "            redis_client.setex(redis_key, 60*60*24, str(data))\n",
    "            # Chuy·ªÉn ƒë·ªïi l·∫°i chu·ªói ƒë·∫∑c bi·ªát th√†nh None tr∆∞·ªõc khi ƒë·∫©y d·ªØ li·ªáu v√†o DB\n",
    "            data = {k: (v if v != \"None\" else None) for k, v in data.items()}\n",
    "            # L∆∞u tr·ªØ d·ªØ li·ªáu v√†o DB\n",
    "            conn = PostgresTool(**db_config)\n",
    "            conn.push_data('match', data)\n",
    "            conn.close()\n",
    "        else:\n",
    "            print(emoji.emojize(f\"ü¶Ñüë©üèª‚Äçüíª {redis_prefix} Duplicate data found, skipping: {data} ü¶Ñ\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(db_config, \"dbBBSW\")\n",
    "    # main(db_config_sv, \"dbAWS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# picker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.header import read_headers_from_config\n",
    "from Utils.params import read_params_from_config\n",
    "import configparser\n",
    "from Utils.postgres_tool import PostgresTool\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import requests\n",
    "import redis\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "\n",
    "headers = read_headers_from_config(\"./config/config.ini\")\n",
    "params = read_params_from_config(\"./config/config.ini\")\n",
    "url_picker = config['url']['URL_PICKER']\n",
    "db_config = {\n",
    "    \"host\": config['database_sv']['DB_SV_HOSTS'],\n",
    "    \"port\": config['database_sv'].getint('DB_SV_PORT'),\n",
    "    \"user\": config['database_sv']['DB_SV_USER'],\n",
    "    \"password\": config['database_sv']['DB_SV_PASSWORD'],\n",
    "    \"database\": config['database_sv']['DB_SV_DATABASE']\n",
    "}\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6377, db=0)\n",
    "redis_set_key = \"unique_get_picker_ids_test\"\n",
    "\n",
    "def fetch_data_from_url(url, headers, params):\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()  # Ensure we catch any HTTP errors\n",
    "    return response.json()[\"picks\"]\n",
    "\n",
    "def process_pick_data(data, gameType):\n",
    "    for i in data:\n",
    "        for game, pick in i[\"picks\"].items():\n",
    "            datas = {\n",
    "                \"match_id\": game,\n",
    "                \"date_add\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                \"status_update\": True,\n",
    "                \"stake\": pick.get(\"stake\"),\n",
    "                \"seq\": pick.get(\"seq\"),\n",
    "                \"result\": pick.get(\"result\"),\n",
    "                \"win_pct\": i.get(\"season_win_pct\", 0)  # Default to 0 if season_win_pct is missing\n",
    "            }\n",
    "            if gameType == \"ats\":\n",
    "                if \"spread\" in pick and \"team_id\" in pick and i.get(\"win_pct\", 0) >= 55:\n",
    "                    datas[\"spread\"] = pick[\"spread\"]\n",
    "                    datas[\"team_id\"] = pick[\"team_id\"]\n",
    "                    yield datas\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                if \"ou_type\" in pick and \"ou_value\" in pick and i.get(\"win_pct\", 0) >= 51:\n",
    "                    datas[\"ou_type\"] = pick[\"ou_type\"]\n",
    "                    datas[\"ou_value\"] = pick[\"ou_value\"]\n",
    "                    yield datas\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "def delete_redis_key(key_pattern):\n",
    "    keys = redis_client.keys(key_pattern)\n",
    "    if keys:\n",
    "        redis_client.delete(*keys)\n",
    "        print(f\"Deleted keys: {keys}\")\n",
    "    else:\n",
    "        print(\"No keys found to delete.\")\n",
    "\n",
    "def get_us_date(timezone_name='US/Eastern'):\n",
    "    us_timezone = pytz.timezone(timezone_name)\n",
    "    utc_now = datetime.now(pytz.utc)\n",
    "    us_now = utc_now.astimezone(us_timezone)\n",
    "    return us_now.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_picker(tournament, season, gameType, db_config,season_date):\n",
    "    conn = PostgresTool(**db_config)\n",
    "    CURRENT_DATE_US = get_us_date()\n",
    "\n",
    "    query = f\"SELECT idx FROM date_id WHERE date_play = '{CURRENT_DATE_US}' and sport_id = '{tournament}' and season = '{season_date}'\"\n",
    "    idx = conn.query(query, False)[0][0]\n",
    "\n",
    "    list_url = [url_picker.format(tournament, season, idx, gameType, sequence) for sequence in range(0, 150, 50)]\n",
    "    for url in list_url:\n",
    "        data = fetch_data_from_url(url, headers, params)\n",
    "        for datas in process_pick_data(data, gameType):\n",
    "            redis_key = f\"Picker{datas}\"\n",
    "            print(datas)\n",
    "            # exists = redis_client.sismember(redis_set_key, str(datas))\n",
    "            \n",
    "            # if not exists:\n",
    "            #     redis_client.sadd(redis_set_key,str(datas))\n",
    "            #     redis_client.expire(redis_set_key, 60*60*24)\n",
    "            #     redis_client.setex(redis_key, 60*60*24, str(datas))\n",
    "            #     datas = {k: v for k, v in datas.items() if v is not None}\n",
    "            #     if datas.get(\"win_pct\") >= 55 and gameType == \"ats\" and datas.get(\"result\") == \"pregame\":\n",
    "            #         print([datas])\n",
    "            #         # conn.push_data(f\"expert_{gameType}\",datas)\n",
    "            #     # elif datas.get(\"win_pct\") >= 51 and gameType == \"ou\" and datas.get(\"result\") == \"pregame\":\n",
    "            #         # conn.push_data(f\"expert_{gameType}\",datas)\n",
    "            #     else:\n",
    "            #         continue\n",
    "            # else:\n",
    "            #     print(f\"ü¶Ñüë©üèª‚Äçüíª Duplicate data found, skipping: {datas}\")\n",
    "    conn.close()\n",
    "\n",
    "def main():\n",
    "    delete_redis_key(\"Picker*\")  # X√≥a c√°c key Redis tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu\n",
    "    # get_picker(\"mlb\", \"2024\", \"ats\", db_config,\"2024\")\n",
    "    get_picker(\"mlb\", \"2024\", \"ou\", db_config,\"2024\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\"match_id\": \"9089\", \"date_add\": \"2024-07-22\", \"status_update\": True, \"stake\": 0, \"seq\": 3, \"result\": \"pregame\", \"win_pct\": 51.939, \"ou_type\": \"under\", \"ou_value\": 8.5}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
